# Analyzer Example
Repo with len input/output analyzer.


## PROD BUILD
1. Создайте файл .env из примера .env.example и заполните его.
2. Развертывание: `source docker/deploy.sh up`
3. Добавить анализатор в основной сервис через метод `/admin/add_analyzer`


## DEV BUILD
1. `conda create -n lh_len_analyzer python=3.11`
2. `conda activate lh_len_analyzer`
3. `pip install -r requirements/dev.txt`
4. `pre-commit install` — установка прекоммитов
5. `pre-commit run --all-files` — проверка кодстайла (будет запускаться автоматически при коммитах)

Для локального тестирования использовать: `source docker/deploy.sh up`


## Указания к разработке
Каждый анализатор может иметь на `/analyzer/input`, так и `analyzer/output` методы.

1. Вам необходимо создать модель [Vault](./app/models/vault.py) — данные, которые необходимо добавить пользователю для работы анализатора:
    - Параметры, чтобы определять reject_flg(флаг того, что текст не прошел проверку)
    - Параметры конкретно для модели (например, системный промпт, который не должна модель выдавать пользователю)

    Для одного эндпоинта один `Vault`. Соответственно, если для входа и выхода нужны разные параметры, то они все равно должны храниться в одном "сейфе".

2. Затем вам нужно создать модель в [/app/services/model.py](./app/services/model.py), где будет определена основная логика проверки:
    - Вы можете разделить логику проверки input и output текстов.
    - Каждый метод принимает `text` — сообщение пользователя или ответ модели, а также `Vault`, который вы определили на первом этапе.

3. Следующим этапом вам нужно убедиться, что сам [сервис анализатора](./app/services/analyzer.py) корректно использует вашу модель.

4. Также необходимо проверить, что docker контейнер поднимается без ошибок. (для этого придется либо поднять локально clickhouse и lighthouse-server, либо вставить креды удаленного clickhouse).
